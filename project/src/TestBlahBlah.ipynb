{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import GlobalParameters\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords\n",
    "nltkStopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'a',\n",
       "           'about',\n",
       "           'above',\n",
       "           'across',\n",
       "           'after',\n",
       "           'afterwards',\n",
       "           'again',\n",
       "           'against',\n",
       "           'all',\n",
       "           'almost',\n",
       "           'alone',\n",
       "           'along',\n",
       "           'already',\n",
       "           'also',\n",
       "           'although',\n",
       "           'always',\n",
       "           'am',\n",
       "           'among',\n",
       "           'amongst',\n",
       "           'amoungst',\n",
       "           'amount',\n",
       "           'an',\n",
       "           'and',\n",
       "           'another',\n",
       "           'any',\n",
       "           'anyhow',\n",
       "           'anyone',\n",
       "           'anything',\n",
       "           'anyway',\n",
       "           'anywhere',\n",
       "           'are',\n",
       "           'around',\n",
       "           'as',\n",
       "           'at',\n",
       "           'back',\n",
       "           'be',\n",
       "           'became',\n",
       "           'because',\n",
       "           'become',\n",
       "           'becomes',\n",
       "           'becoming',\n",
       "           'been',\n",
       "           'before',\n",
       "           'beforehand',\n",
       "           'behind',\n",
       "           'being',\n",
       "           'below',\n",
       "           'beside',\n",
       "           'besides',\n",
       "           'between',\n",
       "           'beyond',\n",
       "           'bill',\n",
       "           'both',\n",
       "           'bottom',\n",
       "           'but',\n",
       "           'by',\n",
       "           'call',\n",
       "           'can',\n",
       "           'cannot',\n",
       "           'cant',\n",
       "           'co',\n",
       "           'con',\n",
       "           'could',\n",
       "           'couldnt',\n",
       "           'cry',\n",
       "           'de',\n",
       "           'describe',\n",
       "           'detail',\n",
       "           'do',\n",
       "           'done',\n",
       "           'down',\n",
       "           'due',\n",
       "           'during',\n",
       "           'each',\n",
       "           'eg',\n",
       "           'eight',\n",
       "           'either',\n",
       "           'eleven',\n",
       "           'else',\n",
       "           'elsewhere',\n",
       "           'empty',\n",
       "           'enough',\n",
       "           'etc',\n",
       "           'even',\n",
       "           'ever',\n",
       "           'every',\n",
       "           'everyone',\n",
       "           'everything',\n",
       "           'everywhere',\n",
       "           'except',\n",
       "           'few',\n",
       "           'fifteen',\n",
       "           'fifty',\n",
       "           'fill',\n",
       "           'find',\n",
       "           'fire',\n",
       "           'first',\n",
       "           'five',\n",
       "           'for',\n",
       "           'former',\n",
       "           'formerly',\n",
       "           'forty',\n",
       "           'found',\n",
       "           'four',\n",
       "           'from',\n",
       "           'front',\n",
       "           'full',\n",
       "           'further',\n",
       "           'get',\n",
       "           'give',\n",
       "           'go',\n",
       "           'had',\n",
       "           'has',\n",
       "           'hasnt',\n",
       "           'have',\n",
       "           'he',\n",
       "           'hence',\n",
       "           'her',\n",
       "           'here',\n",
       "           'hereafter',\n",
       "           'hereby',\n",
       "           'herein',\n",
       "           'hereupon',\n",
       "           'hers',\n",
       "           'herself',\n",
       "           'him',\n",
       "           'himself',\n",
       "           'his',\n",
       "           'how',\n",
       "           'however',\n",
       "           'hundred',\n",
       "           'i',\n",
       "           'ie',\n",
       "           'if',\n",
       "           'in',\n",
       "           'inc',\n",
       "           'indeed',\n",
       "           'interest',\n",
       "           'into',\n",
       "           'is',\n",
       "           'it',\n",
       "           'its',\n",
       "           'itself',\n",
       "           'keep',\n",
       "           'last',\n",
       "           'latter',\n",
       "           'latterly',\n",
       "           'least',\n",
       "           'less',\n",
       "           'ltd',\n",
       "           'made',\n",
       "           'many',\n",
       "           'may',\n",
       "           'me',\n",
       "           'meanwhile',\n",
       "           'might',\n",
       "           'mill',\n",
       "           'mine',\n",
       "           'more',\n",
       "           'moreover',\n",
       "           'most',\n",
       "           'mostly',\n",
       "           'move',\n",
       "           'much',\n",
       "           'must',\n",
       "           'my',\n",
       "           'myself',\n",
       "           'name',\n",
       "           'namely',\n",
       "           'neither',\n",
       "           'never',\n",
       "           'nevertheless',\n",
       "           'next',\n",
       "           'nine',\n",
       "           'no',\n",
       "           'nobody',\n",
       "           'none',\n",
       "           'noone',\n",
       "           'nor',\n",
       "           'not',\n",
       "           'nothing',\n",
       "           'now',\n",
       "           'nowhere',\n",
       "           'of',\n",
       "           'off',\n",
       "           'often',\n",
       "           'on',\n",
       "           'once',\n",
       "           'one',\n",
       "           'only',\n",
       "           'onto',\n",
       "           'or',\n",
       "           'other',\n",
       "           'others',\n",
       "           'otherwise',\n",
       "           'our',\n",
       "           'ours',\n",
       "           'ourselves',\n",
       "           'out',\n",
       "           'over',\n",
       "           'own',\n",
       "           'part',\n",
       "           'per',\n",
       "           'perhaps',\n",
       "           'please',\n",
       "           'put',\n",
       "           'rather',\n",
       "           're',\n",
       "           'same',\n",
       "           'see',\n",
       "           'seem',\n",
       "           'seemed',\n",
       "           'seeming',\n",
       "           'seems',\n",
       "           'serious',\n",
       "           'several',\n",
       "           'she',\n",
       "           'should',\n",
       "           'show',\n",
       "           'side',\n",
       "           'since',\n",
       "           'sincere',\n",
       "           'six',\n",
       "           'sixty',\n",
       "           'so',\n",
       "           'some',\n",
       "           'somehow',\n",
       "           'someone',\n",
       "           'something',\n",
       "           'sometime',\n",
       "           'sometimes',\n",
       "           'somewhere',\n",
       "           'still',\n",
       "           'such',\n",
       "           'system',\n",
       "           'take',\n",
       "           'ten',\n",
       "           'than',\n",
       "           'that',\n",
       "           'the',\n",
       "           'their',\n",
       "           'them',\n",
       "           'themselves',\n",
       "           'then',\n",
       "           'thence',\n",
       "           'there',\n",
       "           'thereafter',\n",
       "           'thereby',\n",
       "           'therefore',\n",
       "           'therein',\n",
       "           'thereupon',\n",
       "           'these',\n",
       "           'they',\n",
       "           'thick',\n",
       "           'thin',\n",
       "           'third',\n",
       "           'this',\n",
       "           'those',\n",
       "           'though',\n",
       "           'three',\n",
       "           'through',\n",
       "           'throughout',\n",
       "           'thru',\n",
       "           'thus',\n",
       "           'to',\n",
       "           'together',\n",
       "           'too',\n",
       "           'top',\n",
       "           'toward',\n",
       "           'towards',\n",
       "           'twelve',\n",
       "           'twenty',\n",
       "           'two',\n",
       "           'un',\n",
       "           'under',\n",
       "           'until',\n",
       "           'up',\n",
       "           'upon',\n",
       "           'us',\n",
       "           'very',\n",
       "           'via',\n",
       "           'was',\n",
       "           'we',\n",
       "           'well',\n",
       "           'were',\n",
       "           'what',\n",
       "           'whatever',\n",
       "           'when',\n",
       "           'whence',\n",
       "           'whenever',\n",
       "           'where',\n",
       "           'whereafter',\n",
       "           'whereas',\n",
       "           'whereby',\n",
       "           'wherein',\n",
       "           'whereupon',\n",
       "           'wherever',\n",
       "           'whether',\n",
       "           'which',\n",
       "           'while',\n",
       "           'whither',\n",
       "           'who',\n",
       "           'whoever',\n",
       "           'whole',\n",
       "           'whom',\n",
       "           'whose',\n",
       "           'why',\n",
       "           'will',\n",
       "           'with',\n",
       "           'within',\n",
       "           'without',\n",
       "           'would',\n",
       "           'yet',\n",
       "           'you',\n",
       "           'your',\n",
       "           'yours',\n",
       "           'yourself',\n",
       "           'yourselves'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot\n",
      "across\n",
      "inc\n",
      "found\n",
      "less\n",
      "upon\n",
      "within\n",
      "fire\n",
      "afterwards\n",
      "bottom\n",
      "whether\n",
      "fill\n",
      "several\n",
      "serious\n",
      "besides\n",
      "hasnt\n",
      "hereby\n",
      "everywhere\n",
      "would\n",
      "take\n",
      "although\n",
      "many\n",
      "behind\n",
      "put\n",
      "ten\n",
      "former\n",
      "meanwhile\n",
      "whenever\n",
      "whereafter\n",
      "back\n",
      "mine\n",
      "nevertheless\n",
      "go\n",
      "cry\n",
      "alone\n",
      "thin\n",
      "five\n",
      "empty\n",
      "elsewhere\n",
      "sixty\n",
      "two\n",
      "detail\n",
      "therein\n",
      "become\n",
      "never\n",
      "onto\n",
      "must\n",
      "neither\n",
      "amongst\n",
      "either\n",
      "eight\n",
      "everyone\n",
      "becoming\n",
      "without\n",
      "anywhere\n",
      "amount\n",
      "namely\n",
      "hence\n",
      "therefore\n",
      "however\n",
      "sometime\n",
      "almost\n",
      "much\n",
      "noone\n",
      "toward\n",
      "might\n",
      "whatever\n",
      "seem\n",
      "nothing\n",
      "done\n",
      "seems\n",
      "often\n",
      "thereafter\n",
      "perhaps\n",
      "hereafter\n",
      "made\n",
      "since\n",
      "among\n",
      "became\n",
      "full\n",
      "anyway\n",
      "via\n",
      "amoungst\n",
      "others\n",
      "three\n",
      "top\n",
      "beyond\n",
      "beforehand\n",
      "nobody\n",
      "side\n",
      "seeming\n",
      "somehow\n",
      "mostly\n",
      "name\n",
      "formerly\n",
      "otherwise\n",
      "whereas\n",
      "every\n",
      "latter\n",
      "moreover\n",
      "together\n",
      "front\n",
      "last\n",
      "sincere\n",
      "along\n",
      "except\n",
      "show\n",
      "de\n",
      "seemed\n",
      "could\n",
      "fifteen\n",
      "whose\n",
      "thus\n",
      "please\n",
      "thru\n",
      "around\n",
      "enough\n",
      "thence\n",
      "hereupon\n",
      "six\n",
      "hundred\n",
      "nine\n",
      "call\n",
      "even\n",
      "may\n",
      "give\n",
      "ie\n",
      "interest\n",
      "us\n",
      "wherever\n",
      "whoever\n",
      "describe\n",
      "wherein\n",
      "someone\n",
      "else\n",
      "everything\n",
      "find\n",
      "cant\n",
      "first\n",
      "anyone\n",
      "thereupon\n",
      "though\n",
      "eleven\n",
      "well\n",
      "etc\n",
      "one\n",
      "mill\n",
      "rather\n",
      "beside\n",
      "per\n",
      "latterly\n",
      "herein\n",
      "whereby\n",
      "thereby\n",
      "anything\n",
      "couldnt\n",
      "indeed\n",
      "forty\n",
      "throughout\n",
      "whence\n",
      "towards\n",
      "yet\n",
      "none\n",
      "still\n",
      "whole\n",
      "un\n",
      "whither\n",
      "nowhere\n",
      "third\n",
      "thick\n",
      "co\n",
      "ever\n",
      "next\n",
      "already\n",
      "four\n",
      "least\n",
      "somewhere\n",
      "anyhow\n",
      "also\n",
      "ltd\n",
      "eg\n",
      "con\n",
      "twelve\n",
      "whereupon\n",
      "fifty\n",
      "another\n",
      "always\n",
      "sometimes\n",
      "part\n",
      "bill\n",
      "system\n",
      "due\n",
      "move\n",
      "something\n",
      "see\n",
      "get\n",
      "twenty\n",
      "becomes\n",
      "keep\n"
     ]
    }
   ],
   "source": [
    "for word in ENGLISH_STOP_WORDS:\n",
    "    if word not in nltkStopWords:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltkStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should've\n",
      "needn't\n",
      "s\n",
      "o\n",
      "shouldn\n",
      "isn\n",
      "m\n",
      "aren't\n",
      "doing\n",
      "needn\n",
      "y\n",
      "mightn't\n",
      "didn't\n",
      "hasn\n",
      "wasn't\n",
      "weren\n",
      "wouldn\n",
      "she's\n",
      "mustn\n",
      "shan't\n",
      "d\n",
      "ma\n",
      "hasn't\n",
      "that'll\n",
      "aren\n",
      "you'll\n",
      "shan\n",
      "t\n",
      "mightn\n",
      "ve\n",
      "weren't\n",
      "hadn't\n",
      "it's\n",
      "couldn\n",
      "having\n",
      "theirs\n",
      "won\n",
      "don\n",
      "couldn't\n",
      "just\n",
      "you'd\n",
      "ll\n",
      "haven\n",
      "isn't\n",
      "you're\n",
      "doesn't\n",
      "wouldn't\n",
      "did\n",
      "hadn\n",
      "doesn\n",
      "didn\n",
      "ain\n",
      "mustn't\n",
      "shouldn't\n",
      "don't\n",
      "won't\n",
      "haven't\n",
      "you've\n",
      "wasn\n",
      "does\n"
     ]
    }
   ],
   "source": [
    "for word in nltkStopWords:\n",
    "    if word not in ENGLISH_STOP_WORDS:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404287, 6)\n",
      "(2345796, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vars=GlobalParameters.GlobalVariables()\n",
    "print(vars.train.shape)\n",
    "print(vars.test.shape)\n",
    "vars.test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from file: C:\\Users\\tihor\\Documents\\ml_data_files\\glove_small.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 9526.87it/s]\n"
     ]
    }
   ],
   "source": [
    "from deep_learning_models.word_and_character_vectors import get_char,get_glove,PAD_ID,UNK_ID\n",
    "from deep_learning_models.sentence_operations import sentence_to_word_ids,pad_words,convert_ids_to_word_vectors\n",
    "emb_matrix_word, word2id, id2word=get_glove('C:\\\\Users\\\\tihor\\\\Documents\\\\ml_data_files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_split_words</th>\n",
       "      <th>q2_split_words</th>\n",
       "      <th>q1_ids_padded</th>\n",
       "      <th>q2_ids_padded</th>\n",
       "      <th>q1_glove</th>\n",
       "      <th>q2_glove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[What, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[What, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[1, 11, 3, 916, 25, 916, 724, 6, 4774, 9, 500,...</td>\n",
       "      <td>[1, 11, 3, 916, 25, 916, 724, 6, 4774, 9, 500,...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[What, is, the, story, of, Kohinoor, (Koh-i-No...</td>\n",
       "      <td>[What, would, happen, if, the, Indian, governm...</td>\n",
       "      <td>[1, 11, 3, 387, 7, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 77, 1310, 51, 3, 1, 403, 1, 3, 1, 1, 2169,...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>[How, can, I, increase, the, speed, of, my, in...</td>\n",
       "      <td>[How, can, Internet, speed, be, increased, by,...</td>\n",
       "      <td>[1, 45, 1, 1014, 3, 966, 7, 44, 354, 1404, 177...</td>\n",
       "      <td>[1, 45, 1, 966, 29, 1729, 25, 1, 156, 1, 0, 0,...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Why, am, I, mentally, very, lonely?, How, can...</td>\n",
       "      <td>[Find, the, remainder, when, [math]23^{24}[/ma...</td>\n",
       "      <td>[1, 89, 1, 1, 114, 1, 1, 45, 1, 4025, 1, 0, 0,...</td>\n",
       "      <td>[1, 3, 1, 68, 1, 11, 1, 25, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>[Which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>[Which, fish, would, survive, in, salt, water?]</td>\n",
       "      <td>[1, 52, 1, 9, 287, 1, 1, 1, 1, 5, 2876, 3411, ...</td>\n",
       "      <td>[1, 1333, 77, 4598, 9, 2236, 1, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "      <td>[[-0.7783306234148628, -0.37085301094094447, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                      q1_split_words  \\\n",
       "0  [What, is, the, step, by, step, guide, to, inv...   \n",
       "1  [What, is, the, story, of, Kohinoor, (Koh-i-No...   \n",
       "2  [How, can, I, increase, the, speed, of, my, in...   \n",
       "3  [Why, am, I, mentally, very, lonely?, How, can...   \n",
       "4  [Which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                      q2_split_words  \\\n",
       "0  [What, is, the, step, by, step, guide, to, inv...   \n",
       "1  [What, would, happen, if, the, Indian, governm...   \n",
       "2  [How, can, Internet, speed, be, increased, by,...   \n",
       "3  [Find, the, remainder, when, [math]23^{24}[/ma...   \n",
       "4    [Which, fish, would, survive, in, salt, water?]   \n",
       "\n",
       "                                       q1_ids_padded  \\\n",
       "0  [1, 11, 3, 916, 25, 916, 724, 6, 4774, 9, 500,...   \n",
       "1  [1, 11, 3, 387, 7, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [1, 45, 1, 1014, 3, 966, 7, 44, 354, 1404, 177...   \n",
       "3  [1, 89, 1, 1, 114, 1, 1, 45, 1, 4025, 1, 0, 0,...   \n",
       "4  [1, 52, 1, 9, 287, 1, 1, 1, 1, 5, 2876, 3411, ...   \n",
       "\n",
       "                                       q2_ids_padded  \\\n",
       "0  [1, 11, 3, 916, 25, 916, 724, 6, 4774, 9, 500,...   \n",
       "1  [1, 77, 1310, 51, 3, 1, 403, 1, 3, 1, 1, 2169,...   \n",
       "2  [1, 45, 1, 966, 29, 1729, 25, 1, 156, 1, 0, 0,...   \n",
       "3  [1, 3, 1, 68, 1, 11, 1, 25, 1, 0, 0, 0, 0, 0, ...   \n",
       "4  [1, 1333, 77, 4598, 9, 2236, 1, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                            q1_glove  \\\n",
       "0  [[-0.7783306234148628, -0.37085301094094447, -...   \n",
       "1  [[-0.7783306234148628, -0.37085301094094447, -...   \n",
       "2  [[-0.7783306234148628, -0.37085301094094447, -...   \n",
       "3  [[-0.7783306234148628, -0.37085301094094447, -...   \n",
       "4  [[-0.7783306234148628, -0.37085301094094447, -...   \n",
       "\n",
       "                                            q2_glove  \n",
       "0  [[-0.7783306234148628, -0.37085301094094447, -...  \n",
       "1  [[-0.7783306234148628, -0.37085301094094447, -...  \n",
       "2  [[-0.7783306234148628, -0.37085301094094447, -...  \n",
       "3  [[-0.7783306234148628, -0.37085301094094447, -...  \n",
       "4  [[-0.7783306234148628, -0.37085301094094447, -...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset=vars.train[0:100].copy()\n",
    "data_subset['q1_ids_padded']=data_subset['question1'].apply(lambda x:pad_words(sentence_to_word_ids(x,word2id)[1],237))\n",
    "data_subset['q2_ids_padded']=data_subset['question2'].apply(lambda x:pad_words(sentence_to_word_ids(x,word2id)[1],237))\n",
    "data_subset['q1_glove']=data_subset['q1_ids_padded'].apply(lambda x:convert_ids_to_word_vectors(x,emb_matrix_word))\n",
    "data_subset['q2_glove']=data_subset['q2_ids_padded'].apply(lambda x:convert_ids_to_word_vectors(x,emb_matrix_word))\n",
    "data_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 237, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "zz=data_subset['q1_glove'].tolist()\n",
    "aa=np.array(zz)\n",
    "aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>word_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  word_match  \n",
       "0  What is the step by step guide to invest in sh...             0    0.727273  \n",
       "1  What would happen if the Indian government sto...             0    0.333333  \n",
       "2  How can Internet speed be increased by hacking...             0    0.363636  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0    0.000000  \n",
       "4            Which fish would survive in salt water?             0    0.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.train['word_match']=vars.train.apply(lambda row:word_match_score(row['question1'],row['question2'],stops),axis=1)\n",
    "vars.train['']\n",
    "vars.train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_match_score(sentence1,sentence2,stopwords):\n",
    "    sentence1Words={}\n",
    "    sentence2Words={}\n",
    "    for word in sentence1.lower().split():\n",
    "        if word not in stopwords:\n",
    "            sentence1Words[word]=1\n",
    "    for word in sentence2.lower().split():\n",
    "        if word not in stopwords:\n",
    "            sentence2Words[word]=1\n",
    "    if len(sentence1Words)==0 or len(sentence2Words)==0:\n",
    "        return 0\n",
    "    common_words_sentence1=[]\n",
    "    common_words_sentence2=[]\n",
    "    for word in sentence1Words:\n",
    "        if word in sentence2Words:\n",
    "            common_words_sentence1.append(word)\n",
    "    for word in sentence2Words:\n",
    "        if word in sentence1Words:\n",
    "            common_words_sentence1.append(word)\n",
    "    score=(len(common_words_sentence1)+len(common_words_sentence2))/(len(sentence1Words)+len(sentence2Words))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_match_score(lala[0],lala[1],stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops=set(stopwords.words(\"english\"))\n",
    "stops=set(ENGLISH_STOP_WORDS)\n",
    "def word_match(s1,s2):\n",
    "    q1Words={}\n",
    "    q2Words={}\n",
    "    for word in str(s1).lower().split():\n",
    "        if word not in stops:\n",
    "            q1Words[word]=1\n",
    "    for word in str(s2).lower().split():\n",
    "        if word not in stops:\n",
    "            q2Words[word]=1\n",
    "    if len(q1Words)==0 or len(q2Words)==0:\n",
    "        return 0\n",
    "    shared_words_in_q1=[w for w in q1Words.keys() if w in q2Words]\n",
    "    shared_words_in_q2=[w for w in q2Words.keys() if w in q1Words]\n",
    "    R=(len(shared_words_in_q1)+len(shared_words_in_q2))/(len(q1Words)+len(q2Words))\n",
    "    return R\n",
    "word_match(lala[0],lala[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# If a word appears only once, we ignore it completely (likely a typo)\n",
    "# Epsilon defines a smoothing constant, which makes the effect of extremely rare words smaller\n",
    "def get_weight(count, eps=0, min_count=2):\n",
    "    if count < min_count:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 / (count + eps)\n",
    "\n",
    "eps = 0\n",
    "words = (\" \".join(lala)).lower().split()\n",
    "counts = Counter(words)\n",
    "weights = {word: get_weight(count) for word, count in counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'an': 0,\n",
       " 'conclusive': 0,\n",
       " 'inconclusive': 0,\n",
       " 'is': 0.5,\n",
       " 'test': 0.5,\n",
       " 'that': 0,\n",
       " 'this': 0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_word_match_share(q1,q2):\n",
    "    q1words = {}\n",
    "    q2words = {}\n",
    "    for word in q1.lower().split():\n",
    "        if word not in stops:\n",
    "            q1words[word] = 1\n",
    "    for word in q2.lower().split():\n",
    "        if word not in stops:\n",
    "            q2words[word] = 1\n",
    "    if len(q1words) == 0 or len(q2words) == 0:\n",
    "        # The computer-generated chaff includes a few questions that are nothing but stopwords\n",
    "        return 0\n",
    "    \n",
    "    shared_weights = [weights.get(w, 0) for w in q1words.keys() if w in q2words] + [weights.get(w, 0) for w in q2words.keys() if w in q1words]\n",
    "    total_weights = [weights.get(w, 0) for w in q1words] + [weights.get(w, 0) for w in q2words]\n",
    "    \n",
    "    R = np.sum(shared_weights) / np.sum(total_weights)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "lala=[\"This is an inconclusive test\",\"That is a conclusive test\"]\n",
    "tfidf_word_match_share(lala[0],lala[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(ngram_range=(1,1),stop_words=ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.81480247 0.57973867]]\n",
      "[[0.81480247 0.         0.57973867]]\n"
     ]
    }
   ],
   "source": [
    "all_qs=pd.Series(lala)\n",
    "tfidf.fit(all_qs)\n",
    "print(tfidf.transform([lala[0]]).toarray())\n",
    "print(tfidf.transform([lala[1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_match(question1,question2,tfidfObject):\n",
    "    vector1=tfidfObject.transform(question1).toarray()\n",
    "    vector2=tfidfObject.transform(question2).toarray()\n",
    "    product=vector1*vector2\n",
    "    score=(2*np.sum(vector1*vector2))/(np.sum(vector1)+np.sum(vector2))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24100897143904737\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_match([lala[0]],[lala[1]],tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id      False\n",
       "question1     True\n",
       "question2     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars.test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [test_id, question1, question2]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test=vars.test[vars.test.isnull().any(axis=1)]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379205</th>\n",
       "      <td>379205</td>\n",
       "      <td>How I can learn android app development?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817520</th>\n",
       "      <td>817520</td>\n",
       "      <td>How real can learn android app development?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943911</th>\n",
       "      <td>943911</td>\n",
       "      <td>How app development?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046690</th>\n",
       "      <td>1046690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How I what can learn android app development?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270024</th>\n",
       "      <td>1270024</td>\n",
       "      <td>How I can learn app development?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461432</th>\n",
       "      <td>1461432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>How distinct can learn android app development?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_id                                    question1  \\\n",
       "379205    379205     How I can learn android app development?   \n",
       "817520    817520  How real can learn android app development?   \n",
       "943911    943911                         How app development?   \n",
       "1046690  1046690                                          NaN   \n",
       "1270024  1270024             How I can learn app development?   \n",
       "1461432  1461432                                          NaN   \n",
       "\n",
       "                                               question2  \n",
       "379205                                               NaN  \n",
       "817520                                               NaN  \n",
       "943911                                               NaN  \n",
       "1046690    How I what can learn android app development?  \n",
       "1270024                                              NaN  \n",
       "1461432  How distinct can learn android app development?  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
